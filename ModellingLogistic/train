#!/usr/bin/env Rscript

library(data.table) # Opted for this, 1. Because its really fast 2. dplyr conflicted with plumber
library(rjson) # for handling json data
library(lightgbm)
# use pattern to read data : this is to make the model generic 
fname_train <- dir(path = "./../ml_vol/inputs/data/training/binaryClassificationBaseMainInput/", pattern = "\\_train.csv$")
fname_schema <- dir(path = "./../ml_vol/inputs/data_config/", pattern = "\\_schema.json$")

# read in the schema so that we extract the response variable
dataschema <- fromJSON(file = paste0("./../ml_vol/inputs/data_config/",fname_schema))

# import the training data 
genericdata <- fread(paste0("./../ml_vol/inputs/data/training/binaryClassificationBaseMainInput/",fname_train))

# call the preprocessing pipeline 
source("preprocessor.R")
output_vector <- preprocessing(fname_train=fname_train,fname_schema=fname_schema,genericdata=genericdata,dataschema=dataschema)[[1]]
predictors <- preprocessing(fname_train=fname_train,fname_schema=fname_schema,genericdata=genericdata,dataschema=dataschema)[[5]]
id <- preprocessing(fname_train=fname_train,fname_schema=fname_schema,genericdata=genericdata,dataschema=dataschema)[[2]]
# function to train the model  and save it back into the mounted volume

lets_train <- function(x,y){

  # Train
  lgbm_model <- lightgbm(
    data = x
    , label = y
    , params = list(
      num_leaves = 4L
      , learning_rate = 1.0
      , objective = "binary"
    )
    , nrounds = 10L
    , verbose = -1L
  )

  # save the model into the artifacts folder in the attached volume.
  #saveRDS(lgbm_model, "./../ml_vol/model/artifacts/lgbm_model.rds")
  lightgbm::saveRDS.lgb.Booster(lgbm_model, "./../ml_vol/model/artifacts/lgbm_model.rds")
  saveRDS(id,"./../ml_vol/model/artifacts/id.rds")
   # we'll need this on the serve script (to convert the json data input to a matrix)

}

# calling the model
glmModel <- lets_train(x=predictors, y=output_vector)

